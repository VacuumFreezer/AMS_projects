{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "# Check pytorch version\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  6 17:41:05 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.59                 Driver Version: 556.13         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    On  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   46C    P5             14W /  140W |    1941MiB /   8188MiB |     22%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       317      C   /python3.10                                 N/A      |\n",
      "|    0   N/A  N/A      5084      C   /python3.10                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU for training\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_exp_name = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "seed = 114514\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Avoid nondeterministic algorithms and disable benchmarks for convolution operations\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Pipeline for preprocessing of the image. \n",
    "transform = transforms.Compose([\n",
    "\n",
    "    # Resize into a fixed size\n",
    "    transforms.Resize((32, 32)),\n",
    "\n",
    "    # Transform to pytorch tensorc\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # Normalizes the pixel values to have a mean value of 0 and a standard deviation of 1, assuming initially in range (0, 1)\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=False)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset has 60000 samples.\n",
      "Test dataset has 10000 samples.\n",
      "torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Train dataset has {len(train_dataset)} samples.')\n",
    "print(f'Test dataset has {len(test_dataset)} samples.')\n",
    "\n",
    "# Viualization of the first image\n",
    "image_zero, target_zero = test_dataset[0]\n",
    "print(np.shape(image_zero))\n",
    "plt.imshow(image_zero.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {target_zero}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classfier(nn.Module):\n",
    "    def __init__(self):\n",
    "        # inherit attributes and methods of nn.Module\n",
    "        super(Classfier, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Input size is [32, 32, 1]\n",
    "            self.cnn_layer(in_channels=1, out_channels=64),     # [16, 16, 64]\n",
    "\n",
    "            self.cnn_layer(in_channels=64, out_channels=128),       # [8, 8, 128]\n",
    "\n",
    "            self.cnn_layer(in_channels=128, out_channels=256),      # [4, 4, 256]\n",
    "\n",
    "            self.cnn_layer(in_channels=256, out_channels=512),       # [2, 2, 512]\n",
    "\n",
    "            self.cnn_layer(in_channels=512, out_channels=512)        # [1, 1, 512]\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def cnn_layer(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, \n",
    "                  pooling_kernel_size=2, pooling_stride=2, pooling_padding=0):\n",
    "        \"\"\"\n",
    "        Create a default CNN layer. In and out channels are required parameters\n",
    "        Parameters:\n",
    "        - in_channels: Number of input channels.\n",
    "        - out_channels: Number of output filter channels.\n",
    "        - kernel_size: Size of the convolutional kernel.\n",
    "        - stride: Stride of the convolution.\n",
    "        - padding: Padding value added to the input.\n",
    "        - pooling_kernel_size: Size of the maxpooling kernel.\n",
    "        - pooling_stride: Stride of the maxpooling.\n",
    "        - pooing_padding: Padding value added to the convolution output channel.\n",
    "\n",
    "        Returns:\n",
    "        - nn.Sequential: A block with convolution layer and pooling layer.\n",
    "        \"\"\"\n",
    "\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            # nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(pooling_kernel_size, pooling_stride, pooling_padding)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        filter = self.cnn(x)\n",
    "        filter = filter.view(filter.size()[0], -1)\n",
    "\n",
    "        return self.fc(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load('config.yaml')\n",
    "config_dict = OmegaConf.to_container(config, resolve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide MNIST dataset into training, vaildation and test sets\n",
    "\n",
    "# 48,000 figures as training data, 12,000 figures as validation data\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train, valid = random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=config_dict['batch_size'], shuffle=True)\n",
    "valid_loader = DataLoader(valid, batch_size=config_dict['batch_size'], shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=config_dict['batch_size'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiallize the model to device\n",
    "model = Classfier().to(device)\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = getattr(nn, config_dict['criterion'])()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = config_dict['lr'])\n",
    "\n",
    "patience = config_dict['patience']\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=config_dict['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034a651703c5495683d8417bf140f88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 001/002 ] loss = 0.30827, acc = 0.89477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5db9cc8261541b681234adf79b9f67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 001/002 ] loss = 0.06602, acc = 0.98213\n",
      "Best model found at epoch 0, saving model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb24fe848944afc8ff208ee15f58b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 002/002 ] loss = 0.07173, acc = 0.98046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3de8407a572421ba69a9cc6f9b6c4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Valid | 002/002 ] loss = 0.05198, acc = 0.98795\n",
      "Best model found at epoch 1, saving model\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Start training\n",
    "\"\"\"\n",
    "n_epoches = config_dict['n_epoches']\n",
    "stale = 0\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(n_epoches):\n",
    "\n",
    "    \"\"\" -----  Training  ----- \"\"\"\n",
    "\n",
    "    # Turn to train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "\n",
    "        # Load data and label to device\n",
    "        data, label = batch\n",
    "        data, label = data.to(device), label.to(device)\n",
    "\n",
    "        # Clear gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        output = model(data)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the gradient norms for stable training\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute the accuracy for current batch\n",
    "        acc = (output.argmax(dim=-1) == label).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "    \n",
    "    scheduler.step()\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epoches:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "\n",
    "    \"\"\" -----  Validation  ----- \"\"\"\n",
    "    # Turn to validation mode\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for batch in tqdm(valid_loader):\n",
    "\n",
    "        data, label = batch\n",
    "        data, label = data.to(device), label.to(device)\n",
    "\n",
    "        # No need for gradient computation, so acclerate by no_grad\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            output = model(data)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        acc = (output.argmax(dim=-1) == label).float().mean()\n",
    "\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epoches:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "    # # update logs\n",
    "    # if valid_acc > best_acc:\n",
    "    #     with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "    #         print(f\"[ Valid | {epoch + 1:03d}/{n_epoches:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n",
    "    # else:\n",
    "    #     with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "    #         print(f\"[ Valid | {epoch + 1:03d}/{n_epoches:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "    # save model of best accurancy\n",
    "    if valid_acc > best_acc:\n",
    "        print(f\"Best model found at epoch {epoch}, saving model\")\n",
    "        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n",
    "        best_acc = valid_acc\n",
    "        stale = 0\n",
    "    else:\n",
    "        stale += 1\n",
    "        if stale > patience:\n",
    "            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_317/1718212793.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c70203420ec49819b20ee46d76a3a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_best = Classfier().to(device)\n",
    "# Load the model of the best performance\n",
    "model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
    "model_best.eval()\n",
    "test_acc = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch in tqdm(test_loader):\n",
    "\n",
    "        data, label = batch\n",
    "        data, label = data.to(device), label.to(device)\n",
    "\n",
    "        pred = model_best(data.to(device))\n",
    "        \n",
    "        acc = (pred.argmax(dim=-1) == label).cpu().float().mean()\n",
    "        test_acc.append(acc)\n",
    "\n",
    "test_acc = sum(test_acc) / len(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accurancy is: 0.98905\n"
     ]
    }
   ],
   "source": [
    "print(f'Final test accurancy is: {test_acc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madminer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
